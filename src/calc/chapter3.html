<h1>Chapter 3 | Applications of Differentiation </h1>



<h2>3.1 | Maximum and Minimum Values</h2>

<note>
- An **extremum** (or extreme value) of a function is a point at which a **maximum** or **minimum** value of the function is obtained in some interval.
</note>


<p>Consider Figure  3.1.1:</p>

<div img-row>
    <img src="~/../static/images/calc1/3.1.1a.png">
    <img src="~/../static/images/calc1/3.1.1b.png">
    <img src="~/../static/images/calc1/3.1.1c.png">
</div>

<ul>
    <li>Figure (a) has a maximum, but no minimum, as the interval over which the function is defined is open.</li>
    <li>Figure (b), the function has a minimum, but no maximum; there is a discontinuity in the "natural'' place for the maximum to occur.</li>
    <li>Figure (c) has both a maximum and a minimum; note that the function is continuous and the interval on which it is defined is closed.</li>
</ul>


<h3>The extreme Value Theorem</h3>

<note>
    <h3>The extreme Value Theorem</h3>
    If <tex>f</tex> is continuous on a closed interval <tex>[a, b]</tex>, then <tex>f</tex> attains an absolute maximum value stem:[f(c)] and an absolute minimum value <tex>f(d)</tex> at some numbers <tex>c</tex> and <tex>d</tex> in <tex>[a, b]</tex>.

    <note>
    Functions continuous on a closed interval always attain extreme values.
    </note>
</note>

<h3>Fermat’s Theorem</h3>

<note>
    <h3>Fermat’s Theorem</h3>
    If <tex>f</tex> has a local maximum or minimum at <tex>c</tex>, and if <tex>f^\prime(c)</tex> exists, then <tex>f^\prime(c) = 0</tex>.
</note>

<p><b>In terms of critical numbers, Fermat’s Theorem can be rephrased as follows:</b></p>

<note>
    <h3>Fermat’s Theorem (in terms of critical numbers)</h3>
    If f has a local maximum or minimum at c, then c is a critical number of f.
</note>

<h3>Critical Number</h3>

<p>A critical number of a function <tex>f</tex> is a number <tex>c</tex> in the domain of <tex>f</tex> such that either <texf^\prime(c) = 0></tex> or <tex>f^\prime(c)</tex> does not exist.</p>

<note>
* *Critical numbers* of <tex>f</tex> occur when <tex>f^\prime(c) = 0</tex>, or when <tex>f^\prime(c) = \mathrm{undefined}</tex>.
* Not every critical number gives rise to a maximum or a minimum.
</note>


<p>To find an absolute maximum or minimum of a continuous function on a closed interval, we note that either it is local [in which case it occurs at a critical number by (7)] or it occurs at an endpoint of the interval, as we see from the examples in Figure 8. Thus the following three-step procedure always works. **See The Closed Interval Method.**</p>

<h3>The Closed Interval Method</h3>


<note>
    <h3>The Closed Interval Method</h3>
    To find the absolute maximum and minimum values of a continuous function <tex>f</tex> on a closed interval <tex>[a, b]</tex>:

    <ul>
        <li>Find the values of <tex>f</tex> at the critical numbers of <tex>f</tex> in <tex>(a, b)</tex>. I.e. *critical numbers* of <tex>f</tex> occur when <tex>f^\prime(c) = 0</tex>, or when stem:[f^\prime(c) = \mathrm{undefined}]</li>
        <li>Find the values of <tex>f</tex> at the endpoints of the interval. I.e. <tex>f(a)</tex> and <tex>f(b)</tex>.</li>
        <li>The **largest** of the values from **Steps 1 and 2** is the absolute maximum value; the **smallest** of these values is the absolute minimum value.</li>
    </ul>
</note>

<p>I.e. the maximum/minimum of <tex>f^\prime(c) = 0</tex>, <tex>f(a)</tex>, and <tex>f(b)</tex>.</p>

<p>Using sudo code, the 'The Closed Interval Method' can be defined as the result of:</p>
<tex block>
\begin{equation}
\begin{split}
\mathrm{maximum} &= \mathrm{max}\lbrack f(a), f^\prime(c) = 0, f(b)\rbrack \\
\mathrm{minimum} &= \mathrm{min}\lbrack f(a), f^\prime(c) = 0, f(b)\rbrack
\end{split}
\end{equation}
</tex>

<h2>3.2 | The Mean Value Theorem</h2>

<ul>
    <li><a href='https://www.dpmms.cam.ac.uk/~wtg10/meanvalue.html'>What is the point of the mean value theorem?</a></li>

    <li>The mean value theorem says that the average speed of the car (the slope of the secant line) is equal to the instantaneous speed (slope of the tangent line) at some point(s) in the interval.</li>
</ul>

<blockquote>
    In mathematics, the mean value theorem states, roughly, that for a given planar arc between two endpoints, there is at least one point at which the tangent to the arc is parallel to the secant through its endpoints.
</blockquote>

<p>For any function that is continuous <tex>[a, b]</tex> and differentiable on <tex>(a,b)</tex>, there exists some <tex>c</tex> in the interval <tex>(a,b)</tex> such that the secant joining the endpoints of the <tex>[a, b]</tex> is parallel to the tangent at <tex>c</tex>:</p>

<img block src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Mvt2.svg/520px-Mvt2.svg.png" />

<note>
The function 
f attains the slope of the secant between a and b as the derivative at the point <tex>{\displaystyle \xi \in (a,b)}</tex>:

<img block src='https://upload.wikimedia.org/wikipedia/commons/9/94/Mittelwertsatz3.svg'>

It is also possible that there are multiple tangents parallel to the secant:

<img block src='https://upload.wikimedia.org/wikipedia/commons/f/f9/Mittelwertsatz6.svg'>
</note>


<p>We will see that many of the results of this chapter depend on one central fact, which is called the Mean Value Theorem. But to arrive at the Mean Value Theorem we first need the following result.</p>

<note>
    <h3>Rolle’s Theorem</h3>
    Let f be a function that satisfies the following three hypotheses:

    <ol>
        <li><tex>f</tex> is continuous on the closed interval <tex>[a, b]</tex>.</li>
        <li><tex>f</tex> is differentiable on the open interval <tex>(a, b)</tex>.</li>
        <li><tex>f(a) = f(b)</tex><br>I.e. the x_1 and x_2 map to the same y value.</li>
    </ol>

    Then there is a number <tex>c</tex> in <tex>(a, b)</tex>, such that <texf^\prime(c) = 0></tex>
</note>



<note>
    <h3>The Mean Value Theorem</h3>
    Let <tex>f</tex> be a function that satisfies the following hypotheses:

    <ol>
        <li><tex>f</tex> is continuous on the closed interval <tex>[a, b]</tex>.</li>
        <li><tex>f</tex> is differentiable on the open interval <tex>(a, b)</tex>.</li>
    </ol>

    Then there is a number <tex>c</tex> in <tex>(a, b)</tex>, such that:

    <tex>
    \begin{equation}
    \begin{split}
    f^\prime(c) &= \frac{f(b) - f(a)}{b - a}
    \end{split}
    \end{equation}
    </tex>

    Or, equivalently:

    <tex>
    \begin{equation}
    \begin{split}
    f(b) - f(a) &= f^\prime(c)(b - a)
    \end{split}
    \end{equation}
    </tex>

    Where the tangent at <tex>c</tex> is parallel to the secant line through the endpoints <tex>(a, f(a))</tex> and stem:[(b, f(b))].
</note>


<note>
The Mean Value Theorem is an example of what is called an existence theorem. Like the Intermediate Value Theorem, the Extreme Value Theorem, and Rolle’s Theorem, it guarantees that there exists a number with a certain property, but it doesn’t tell us how to find the number.
</note>

<h3>Miscellaneous</h3>

<note>
    <h3>Theorem (§3.2.5)</h3>
    If stem:[f^\prime(x) = 0] for all x in an interval <tex>(a, b)</tex>, then f is constant on <tex>(a, b)</tex>.
</note>


<note>
    <h3>Corollary (§3.2.7)</h3>
    if stem:[f^\prime(x) = g^\prime(x)] for all stem:[x] in an interval <tex>(a, b)</tex>, then stem:[f - g] is constant on <tex>(a, b)</tex>; that is, stem:[f(x) = g(x) + c] where <tex>c</tex> is a constant.

    <note>
    Corollary 7 says that if two functions have the same derivatives on an interval, then their graphs must be vertical translations of each other there. In other words, the graphs have the same shape, but could be shifted up or down.
    </note>
</note>


<h2>3.3 | How Derivatives Affect the Shape of a Graph</h2>

<p>Many of the applications of calculus depend on our ability to deduce facts about a function f from information concerning its derivatives.
</p>

<p>Because stem:[f^\prime(x)] represents the slope of the curve stem:[y = f(x)] at the point stem:[(x, f(x))], it tells us the direction in which the curve proceeds at each point. So it is reasonable to expect that information about stem:[f^\prime(x)] will provide us with information about stem:[f(x)].</p>

<h3>What Does stem:[f^\prime] Say about <tex>f</tex>?</h3>


<note>
    <h3>Increasing/Decreasing Test</h3>
    <ul>
        <li>If stem:[f^\prime(x) > 0] on an interval, then stem:[f(x)] is increasing on that interval.>
            <br>
            I.e. the tangent lines (in the stem:[f(x)] interval) have positive slope.
        </li>
        <li>If stem:[f^\prime(x) < 0] on an interval, then stem:[f(x)] is decreasing on that interval.
            <br>
            I.e. the tangent lines (in the stem:[f(x)] interval) have negative slope.
        </li>
    </ul>
</note>


<note>
    <h3>The First Derivative Test</h3>
    Suppose that c is a critical number of a continuous function f:

    <ul>
        <li>
            If stem:[f^\prime] changes from positive to negative at <tex>c</tex>, then <tex>f</tex> has a local maximum at <tex>c</tex>.
        </li>
        <li>
            If stem:[f^\prime] changes from negative to positive at <tex>c</tex>, then <tex>f</tex> has a local minimum at <tex>c</tex>.
        </li>
        <li>
            If stem:[f^\prime] is positive to the left and right of <tex>c</tex>, or negative to the left and right of <tex>c</tex>, then <tex>f</tex> has no local maximum or minimum at <tex>c</tex>.
        </li>
    </ul>
</note>

<h3>What Does <tex>f^{\prime\prime}</tex> Say about <tex>f</tex>?</h3>

<note>
If the graph of f lies above all of its tangents on an interval I, then it is called concave upward on I. If the graph of f lies below all of its tangents on I, it is called concave downward on I.
</note>



<note>
    <h3>Concavity Test</h3>
    <ul>
        <li>If <tex>f^{\prime\prime}(x) > 0</tex> for all x in I, then the graph of <tex>f</tex> is concave upward on I.</li>
        <li>If <tex>f^{\prime\prime}(x) < 0</tex> for all x in I, then the graph of <tex>f</tex> is concave downward on I.</li>
    </ul>

    <img src="https://qph.fs.quoracdn.net/main-qimg-4e6db5cc9fb301df3daae9f6c99ccb22">
</note>

<note>
    <h3>Inflection Points</h3>

    A point stem:[P] on a curve stem:[y = f(x)] is called an inflection point if <tex>f</tex> is continuous there and the curve changes from concave upward to concave downward or from concave downward to concave upward at stem:[P].

    <note>
        <p>Quadratic functions have no points of inflection:</p>
        <img style="width: 200px;" src="~/../static/images/common/x-square.png"/>
    </note>
</note>

<note>
    <h3>The Second Derivative Test</h3>
    Suppose <tex>f^{\prime\prime}</tex> is continuous near c:

    <ul>
        <li>If <texf^\prime(c) = 0></tex> and stem:[f^{\prime\prime}(c) > 0], then <tex>f</tex> has a local minimum at <tex>c</tex>.</li>
        <li>If <texf^\prime(c) = 0></tex> and stem:[f^{\prime\prime}(c) < 0], then <tex>f</tex> has a local maximum at <tex>c</tex>.</li>
    </ul>

    <note>
        The Second Derivative Test is inconclusive when stem:[f^{\prime\prime}(c) = 0]. In other words, at such a point there might be a maximum, there might be a minimum, or there might be neither (as in Example 6). This test also fails when stem:[f^{\prime\prime}(c)] does not exist. In such cases the First Derivative Test must be used. In fact, even when both tests apply, the First Derivative Test is often the easier one to use.
    </note>

    <note>
        The second derivative may be used to determine local extrema of a function under certain conditions. If a function has a critical point for which <tex>f^\prime(x) = 0</tex> and the second derivative is positive at this point, then <tex>f</tex> has a local minimum here.
    </note>
</note>


<h2>3.4 | Limits at Infinity; Horizontal Asymptotes</h2>

<note>
    **The professor said:** you can't just apply the limit laws,
    such as for:

    <tex block>
    \lim_{x \to \infty} \frac{x^2 + 3x + 5}{x^3 + 3x + 5}
    </tex>

    Because we don't know if it is continuous.
</note>

<h2>3.5 | Summary Curve Sketching</h2>

<ul>
    <li>For e.g. horizontal asymptotes, don't forgot to add <tex>y = x</tex>, don't just say <tex>x</tex></li>
</ul>

<h2>3.6 | Calculus with Graphing Calculators (Skipped)</h2>
<h2>3.7 | Optimization Problems</h2>
<h2>3.8 | Newtons Method</h2>
<h2>3.9 | Anti-Derivatives</h2>

